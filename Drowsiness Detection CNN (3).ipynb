{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import dlib\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20979, 224, 224), (20979,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load(\"test_data_gray.npy\")\n",
    "y = np.load(\"test_data_label_gray.npy\")\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating training/validation data set from extracted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    training_data = []\n",
    "    training_data_label = []\n",
    "    IMG_SIZE = 224\n",
    "    path = \"D:/training_data\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in os.listdir(path + \"/\" + person):\n",
    "            count = 0\n",
    "            filter = 5\n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                if count % filter == 0:\n",
    "                        \n",
    "                    #check if face is recognizable\n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                        # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                        if landmarks.part(42).x != '':\n",
    "                            if state == \"0\":\n",
    "                                training_data_label.append(np.array(0))\n",
    "                            else:\n",
    "                                training_data_label.append(np.array(1))\n",
    "                            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                            training_data.append(np.array(img))\n",
    "                        break\n",
    "                    \n",
    "                count += 1\n",
    "                        \n",
    "                \n",
    "    np.save(\"training_data_shrunk\", training_data)\n",
    "    np.save(\"training_label_shrunk\", training_data_label)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "#create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    test_data = []\n",
    "    test_data_label = []\n",
    "    IMG_SIZE = 224\n",
    "    path = \"D:/test_data\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in os.listdir(path + \"/\" + person):\n",
    "            count = 0\n",
    "            filter = 5\n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                if count % filter == 0:\n",
    "                    #check if face is recognizable\n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                     # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                        if landmarks.part(42).x != '':\n",
    "                            if state == \"0\":\n",
    "                                test_data_label.append(np.array(0))\n",
    "                            else:\n",
    "                                test_data_label.append(np.array(1))\n",
    "                            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                            test_data.append(np.array(img))\n",
    "                        break\n",
    "                count += 1\n",
    "                \n",
    "    np.save(\"test_data_shrunk\", test_data)\n",
    "    np.save(\"test_label_shrunk\", test_data_label)\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "#create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [08:45<00:00, 10.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:52<00:00,  9.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "create_training_data()\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84973, 224, 224, 3), (84973,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.load(\"training_data_RBG_v3.npy\")\n",
    "\n",
    "y_train = np.load(\"training_data_label_2_classes.npy\")\n",
    "\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21200, 224, 224, 3), (21200,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.load(\"test_data_RBG_v3.npy\")\n",
    "\n",
    "y_test = np.load(\"test_data_label_2_classes.npy\")\n",
    "\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21200, 6), (84973, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain_MLP = np.load(\"training_data_RATIO_v4.npy\")\n",
    "\n",
    "xtest_MLP = np.load(\"test_data_RATIO_v4.npy\")\n",
    "\n",
    "xtest_MLP.shape, xtrain_MLP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38386, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = to_categorical(y_test, num_classes=3)\n",
    "print(y_test[0])\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84973, 224, 224, 3), (84973,), (84973, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, xtrain_MLP = shuffle(x_train, y_train, xtrain_MLP)\n",
    "x_train.shape, y_train.shape, xtrain_MLP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_MLP():\n",
    "    inputs = tf.keras.Input(shape=(6,))\n",
    "    layer = layers.Dense(6, activation='relu')(inputs)\n",
    "    resnet = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                                            input_tensor=tf.keras.Input(shape=(224, 224, 3)))\n",
    "    flatten = layers.Flatten()(resnet.output)\n",
    "    combined = layers.concatenate([flatten, layer])\n",
    "    output = layers.Dense(1, activation='sigmoid')(combined)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[resnet.input, inputs], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84973 samples, validate on 21200 samples\n",
      "Epoch 1/20\n",
      "84973/84973 [==============================] - 797s 9ms/sample - loss: 0.6685 - accuracy: 0.9061 - AUC: 0.9519 - val_loss: 6.1728 - val_accuracy: 0.5097 - val_AUC: 0.4723\n",
      "Epoch 2/20\n",
      "84973/84973 [==============================] - 809s 10ms/sample - loss: 0.4577 - accuracy: 0.9527 - AUC: 0.9793 - val_loss: 6.3957 - val_accuracy: 0.6348 - val_AUC: 0.4720\n",
      "Epoch 3/20\n",
      "84973/84973 [==============================] - 831s 10ms/sample - loss: 0.1610 - accuracy: 0.9777 - AUC: 0.9922 - val_loss: 2.6506 - val_accuracy: 0.5908 - val_AUC: 0.4363\n",
      "Epoch 4/20\n",
      "84973/84973 [==============================] - 813s 10ms/sample - loss: 0.1068 - accuracy: 0.9837 - AUC: 0.9941 - val_loss: 3.4825 - val_accuracy: 0.5758 - val_AUC: 0.4209\n",
      "Epoch 5/20\n",
      "84973/84973 [==============================] - 863s 10ms/sample - loss: 0.1054 - accuracy: 0.9849 - AUC: 0.9941 - val_loss: 5.9683 - val_accuracy: 0.6054 - val_AUC: 0.4523\n",
      "Epoch 6/20\n",
      "84973/84973 [==============================] - 859s 10ms/sample - loss: 0.0633 - accuracy: 0.9888 - AUC: 0.9961 - val_loss: 3.3299 - val_accuracy: 0.5703 - val_AUC: 0.5094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1de4be3d588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_MLP()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit([x_train, xtrain_MLP], \n",
    "          y_train,\n",
    "        epochs=20,\n",
    "         batch_size=32,\n",
    "         validation_data=([x_test,xtest_MLP], y_test),\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.0001, \n",
    "                                             patience=3, \n",
    "                                             restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: shrunk_10N\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"shrunk_10N\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50():\n",
    "    resnet = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                                            input_tensor=tf.keras.Input(shape=(224, 224, 3)))\n",
    "    flatten = layers.Flatten()(resnet.output)\n",
    "    dense = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "    dropout = layers.Dropout(0.5)(dense)\n",
    "    output = layers.Dense(3, activation='softmax')(dropout)\n",
    "    model = tf.keras.Model(inputs=resnet.input, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN():\n",
    "    inputs = tf.keras.Input(shape=(224, 224, 1))\n",
    "    layer = layers.Conv2D(8, 3, padding='same')(inputs)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    layer = layers.ReLU()(layer)    \n",
    "    layer = layers.Conv2D(16, 3, padding='same')(layer)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    layer = layers.ReLU()(layer)\n",
    "    layer = layers.MaxPooling2D()(layer)\n",
    "    \n",
    "    layer = layers.Conv2D(32, 3, padding='same')(layer)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    layer = layers.ReLU()(layer)\n",
    "    layer = layers.Conv2D(64, 3, padding='same')(layer)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    layer = layers.ReLU()(layer)\n",
    "    layer = layers.MaxPooling2D()(layer)\n",
    "    \n",
    "    \n",
    "    layer = layers.Flatten()(layer)\n",
    "    layer = layers.Dense(128, activation='relu')(layer)\n",
    "    #layer = layers.Dropout(0.3)(layer)\n",
    "    layer = layers.Dense(1, activation = 'sigmoid')(layer)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs,outputs=layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP():\n",
    "    inputs = tf.keras.Input(shape=(6,))\n",
    "    layer = layers.Dense(32, activation='sigmoid')(inputs)\n",
    "    layer = layers.Dense(64, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(128, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(256, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(512, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(256, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(64, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(32, activation='sigmoid')(layer)\n",
    "    layer = layers.Dense(1, activation='sigmoid')(layer)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84973,), (21200,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = np.load(\"training_data_label_v3.npy\")\n",
    "test_target = np.load(\"test_data_label_v3.npy\")\n",
    "train_target.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84973 samples, validate on 21200 samples\n",
      "Epoch 1/20\n",
      "84973/84973 [==============================] - 10s 120us/sample - loss: 0.0781 - accuracy: 0.3262 - AUC: 0.5001 - val_loss: -0.1744 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 2/20\n",
      "84973/84973 [==============================] - 9s 109us/sample - loss: 0.0729 - accuracy: 0.3262 - AUC: 0.4996 - val_loss: -0.1892 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 3/20\n",
      "84973/84973 [==============================] - 9s 109us/sample - loss: 0.0729 - accuracy: 0.3262 - AUC: 0.4984 - val_loss: -0.1864 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 4/20\n",
      "84973/84973 [==============================] - 10s 113us/sample - loss: 0.0735 - accuracy: 0.3262 - AUC: 0.4992 - val_loss: -0.1747 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 5/20\n",
      "84973/84973 [==============================] - 10s 114us/sample - loss: 0.0728 - accuracy: 0.3262 - AUC: 0.4998 - val_loss: -0.1513 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 6/20\n",
      "84973/84973 [==============================] - 10s 113us/sample - loss: 0.0729 - accuracy: 0.3262 - AUC: 0.4985 - val_loss: -0.1808 - val_accuracy: 0.3644 - val_AUC: 0.5000\n",
      "Epoch 7/20\n",
      "84973/84973 [==============================] - 10s 113us/sample - loss: 0.0733 - accuracy: 0.3262 - AUC: 0.4988 - val_loss: -0.1523 - val_accuracy: 0.3644 - val_AUC: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29de1c7a888>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP()\n",
    "\n",
    "mlp.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "mlp.fit(xtrain_MLP,\n",
    "        train_target,\n",
    "        epochs=20,\n",
    "         batch_size=32,\n",
    "         validation_data=(xtest_MLP, test_target),\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.0001, \n",
    "                                             patience=5, \n",
    "                                             restore_best_weights=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 8000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 200s 10ms/sample - loss: 1.3492 - accuracy: 0.6877 - AUC: 0.8506 - val_loss: 1.3312 - val_accuracy: 0.5159 - val_AUC: 0.7048\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 195s 10ms/sample - loss: 0.2288 - accuracy: 0.9218 - AUC: 0.9848 - val_loss: 0.5232 - val_accuracy: 0.8364 - val_AUC: 0.9497\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 195s 10ms/sample - loss: 0.1105 - accuracy: 0.9636 - AUC: 0.9956 - val_loss: 0.5387 - val_accuracy: 0.8708 - val_AUC: 0.9575\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 194s 10ms/sample - loss: 0.1332 - accuracy: 0.9566 - AUC: 0.9938 - val_loss: 7.3102 - val_accuracy: 0.6053 - val_AUC: 0.7214\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 194s 10ms/sample - loss: 0.1113 - accuracy: 0.9653 - AUC: 0.9954 - val_loss: 0.2997 - val_accuracy: 0.9396 - val_AUC: 0.9809\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 194s 10ms/sample - loss: 0.0829 - accuracy: 0.9736 - AUC: 0.9969 - val_loss: 2.9688 - val_accuracy: 0.6940 - val_AUC: 0.8138\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 191s 10ms/sample - loss: 0.0712 - accuracy: 0.9772 - AUC: 0.9975 - val_loss: 1.6441 - val_accuracy: 0.7661 - val_AUC: 0.8796\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 191s 10ms/sample - loss: 0.0563 - accuracy: 0.9819 - AUC: 0.9983 - val_loss: 0.1477 - val_accuracy: 0.9544 - val_AUC: 0.9928\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 190s 10ms/sample - loss: 0.0837 - accuracy: 0.9760 - AUC: 0.9969 - val_loss: 0.4564 - val_accuracy: 0.9101 - val_AUC: 0.9690\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 196s 10ms/sample - loss: 0.0429 - accuracy: 0.9865 - AUC: 0.9986 - val_loss: 0.2635 - val_accuracy: 0.9090 - val_AUC: 0.9801\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 198s 10ms/sample - loss: 0.0290 - accuracy: 0.9902 - AUC: 0.9993 - val_loss: 0.7889 - val_accuracy: 0.8528 - val_AUC: 0.9389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25a2d686508>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(x_train[:20000],\n",
    "        y_train[:20000],\n",
    "        epochs=20,\n",
    "         batch_size=32,\n",
    "         validation_data=(x_test[:8000], y_test[:8000]),\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.0001, \n",
    "                                             patience=3, \n",
    "                                             restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: CNN_fake\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"CNN_fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16992/21200 [=======================>......] - ETA: 10s - loss: 6298269.3746 - accuracy: 0.6981 - AUC: 0.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-113a54cbdef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m   def predict(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m   def predict(self, model, x, batch_size=None, verbose=0, steps=None,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "r=[]\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    if i % 5 == 0:\n",
    "        x.append(x_train[i])\n",
    "        y.append(y_train[i])\n",
    "        r.append(xtrain_MLP)\n",
    "        \n",
    "x = np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84973 samples, validate on 21200 samples\n",
      "Epoch 1/20\n",
      "   64/84973 [..............................] - ETA: 6:00:12WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[64,1024,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_3/conv4_block2_3_bn/FusedBatchNormV3 (defined at <ipython-input-13-bc600e10ffea>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/AUC/assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_19]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[64,1024,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_3/conv4_block2_3_bn/FusedBatchNormV3 (defined at <ipython-input-13-bc600e10ffea>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_76206]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bc600e10ffea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                                  \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                                  \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                                                  restore_best_weights=True)])\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[64,1024,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_3/conv4_block2_3_bn/FusedBatchNormV3 (defined at <ipython-input-13-bc600e10ffea>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[metrics/AUC/assert_greater_equal/Assert/AssertGuard/pivot_f/_3/_19]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[64,1024,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node model_3/conv4_block2_3_bn/FusedBatchNormV3 (defined at <ipython-input-13-bc600e10ffea>:17) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_76206]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "model2 = CNN_MLP()\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', 'AUC']\n",
    ")\n",
    "\n",
    "model2.fit([x_train, xtrain_MLP], y_train,\n",
    "            shuffle =True,\n",
    "            epochs=20,\n",
    "            batch_size = 64,\n",
    "            validation_data=([x_test,xtest_MLP], y_test),\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                                 min_delta=0.0001,\n",
    "                                                 patience=4,\n",
    "                                                 restore_best_weights=True)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24999 samples, validate on 21200 samples\n",
      "24999/24999 [==============================] - 273s 11ms/sample - loss: 0.2663 - accuracy: 0.8988 - val_loss: 2.5384 - val_accuracy: 0.4941\n",
      "Train on 39972 samples, validate on 21200 samples\n",
      "39972/39972 [==============================] - 412s 10ms/sample - loss: 0.1050 - accuracy: 0.9655 - val_loss: 2.7012 - val_accuracy: 0.6634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2e3e3fc8a08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([x_train[20001:45000], xtrain_MLP[20001:45000]], y_train[20001:45000],\n",
    "            shuffle =True,\n",
    "            epochs=1,\n",
    "            batch_size = 32,\n",
    "            validation_data=([x_test,xtest_MLP], y_test)\n",
    "            #callbacks=[EarlyStopping(monitor='val_loss', \n",
    "             #                                    min_delta=0.0001,\n",
    "              #                                   patience=4,\n",
    "             #                                    restore_best_weights=True)])\n",
    "          )\n",
    "\n",
    "model2.fit([x_train[45001:], xtrain_MLP[45001:]], y_train[45001:],\n",
    "            shuffle =True,\n",
    "            epochs=1,\n",
    "            batch_size = 32,\n",
    "            validation_data=([x_test,xtest_MLP], y_test)\n",
    "            #callbacks=[EarlyStopping(monitor='val_loss', \n",
    "             #                                    min_delta=0.0001,\n",
    "              #                                   patience=4,\n",
    "             #                                    restore_best_weights=True)])\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21200/21200 [==============================] - 50s 2ms/sample - loss: 2.7012 - accuracy: 0.6634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.701225096295141, 0.6634434]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([x_test,xtest_MLP], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: Resnet50_MLP_dropout\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"Resnet50_MLP_dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21200/21200 [==============================] - 52s 2ms/sample - loss: 0.9181 - accuracy: 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9181041660398808, 0.49896225]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate([x_test,xtest_MLP], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Past Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84974 samples, validate on 21202 samples\n",
      "Epoch 1/20\n",
      "84974/84974 [==============================] - 776s 9ms/sample - loss: 0.3732 - accuracy: 0.8983 - val_loss: 4.2246 - val_accuracy: 0.3185\n",
      "Epoch 2/20\n",
      "84974/84974 [==============================] - 770s 9ms/sample - loss: 0.1239 - accuracy: 0.9687 - val_loss: 5.3317 - val_accuracy: 0.3764\n",
      "Epoch 3/20\n",
      "84974/84974 [==============================] - 768s 9ms/sample - loss: 0.0667 - accuracy: 0.9831 - val_loss: 6.7455 - val_accuracy: 0.2343\n",
      "Epoch 4/20\n",
      "84974/84974 [==============================] - 765s 9ms/sample - loss: 0.0418 - accuracy: 0.9880 - val_loss: 6.0145 - val_accuracy: 0.2432\n",
      "Epoch 5/20\n",
      "84974/84974 [==============================] - 771s 9ms/sample - loss: 0.0335 - accuracy: 0.9897 - val_loss: 5.7112 - val_accuracy: 0.2993\n",
      "Epoch 6/20\n",
      "84974/84974 [==============================] - 765s 9ms/sample - loss: 0.0236 - accuracy: 0.9927 - val_loss: 14.7564 - val_accuracy: 0.3088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23fa1c69108>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "         batch_size=32,\n",
    "         validation_data=(x_test, y_test),\n",
    "         callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.0001, \n",
    "                                             patience=5, \n",
    "                                             restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: Resnet50\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"Resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = CNN_MLP()\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84973 samples, validate on 21200 samples\n",
      "Epoch 1/20\n",
      "Train on 84973 samples, validate on 21200 samples\n",
      "Epoch 1/20\n",
      "84973/84973 [==============================] - 1053s 12ms/sample - loss: 1.0580 - accuracy: 0.8424 - val_loss: 4.6135 - val_accuracy: 0.3183\n",
      "84973/84973 [==============================] - 1053s 12ms/sample - loss: 1.0580 - accuracy: 0.8424 - val_loss: 4.6135 - val_accuracy: 0.3183\n",
      "Epoch 2/20\n",
      "\n",
      "84973/84973 [==============================] - 893s 11ms/sample - loss: 0.6184 - accuracy: 0.9425 - val_loss: 6.2376 - val_accuracy: 0.3168\n",
      "84973/84973 [==============================] - 893s 11ms/sample - loss: 0.6184 - accuracy: 0.9425 - val_loss: 6.2376 - val_accuracy: 0.3168\n",
      "Epoch 3/20Epoch 3/20\n",
      "\n",
      "84973/84973 [==============================] - 871s 10ms/sample - loss: 0.4333 - accuracy: 0.9611 - val_loss: 4.2994 - val_accuracy: 0.3287\n",
      "84973/84973 [==============================] - 871s 10ms/sample - loss: 0.4333 - accuracy: 0.9611 - val_loss: 4.2994 - val_accuracy: 0.3287\n",
      "Epoch 4/20\n",
      "Epoch 4/20\n",
      "84973/84973 [==============================] - 864s 10ms/sample - loss: 0.6344 - accuracy: 0.9614 - val_loss: 14.6655 - val_accuracy: 0.2765\n",
      "84973/84973 [==============================] - 864s 10ms/sample - loss: 0.6344 - accuracy: 0.9614 - val_loss: 14.6655 - val_accuracy: 0.2765\n",
      "Epoch 5/20\n",
      "Epoch 5/20\n",
      "84973/84973 [==============================] - 833s 10ms/sample - loss: 0.5751 - accuracy: 0.9601 - val_loss: 9.4857 - val_accuracy: 0.2944\n",
      "Epoch 6/20\n",
      "84973/84973 [==============================] - 833s 10ms/sample - loss: 0.5751 - accuracy: 0.9601 - val_loss: 9.4857 - val_accuracy: 0.2944\n",
      "Epoch 6/20\n",
      "84973/84973 [==============================] - 809s 10ms/sample - loss: 0.2839 - accuracy: 0.9803 - val_loss: 22.3887 - val_accuracy: 0.3480\n",
      "Epoch 7/20\n",
      "84973/84973 [==============================] - 809s 10ms/sample - loss: 0.2839 - accuracy: 0.9803 - val_loss: 22.3887 - val_accuracy: 0.3480\n",
      "Epoch 7/20\n",
      "84973/84973 [==============================] - 856s 10ms/sample - loss: 0.2611 - accuracy: 0.9815 - val_loss: 38.0480 - val_accuracy: 0.2574\n",
      "84973/84973 [==============================] - 856s 10ms/sample - loss: 0.2611 - accuracy: 0.9815 - val_loss: 38.0480 - val_accuracy: 0.2574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2699eacfb08>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2699eacfb08>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([x_train,xtrain_MLP], y_train,\n",
    "        epochs=20,\n",
    "         batch_size = 32,\n",
    "           validation_data=([x_test,xtest_MLP], y_test),\n",
    "             callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                                             min_delta=0.0001,\n",
    "                                             patience=4,\n",
    "                                             restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\M1ss1ing\\anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Resnet50_MLP\\assets\n",
      "INFO:tensorflow:Assets written to: Resnet50_MLP\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Resnet50_MLP\\assets\n",
      "INFO:tensorflow:Assets written to: Resnet50_MLP\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save(\"Resnet50_MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2] *",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
