{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial Feature/Ratio Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from statistics import stdev, mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n",
      "[[258, 139], [280, 120], [305, 121], [324, 139], [306, 146], [281, 144]]\n",
      "[[87, 138], [108, 121], [134, 120], [161, 137], [135, 144], [109, 145]]\n",
      "[[153, 329], [186, 305], [214, 293], [235, 297], [254, 293], [276, 304], [294, 326], [276, 338], [257, 344], [237, 346], [215, 344], [186, 339]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# dont need to run this\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Load the predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "img = cv2.cvtColor(cv2.imread(\"D:/image_data_copy/1/0/image_29.jpg\"), cv2.COLOR_BGR2RGB)\n",
    "faces = detector(img)\n",
    "right_eye = []\n",
    "left_eye = []\n",
    "mouth = []\n",
    "for face in faces:\n",
    "    x1 = face.left() # left point\n",
    "    y1 = face.top() # top point\n",
    "    x2 = face.right() # right point\n",
    "    y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    " # Create landmark object\n",
    "    landmarks = predictor(image=img, box=face)\n",
    "    \n",
    "    # Loop through all the points\n",
    "    for n in range(42, 48):\n",
    "        x = landmarks.part(n).x\n",
    "        y = landmarks.part(n).y\n",
    "        \n",
    "        # Draw a circle\n",
    "        cv2.circle(img=img, center=(x, y), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "        right_eye.append([x,y])\n",
    "        \n",
    "    for j in range(36, 42):\n",
    "        x = landmarks.part(j).x\n",
    "        y = landmarks.part(j).y\n",
    "        \n",
    "        # Draw a circle\n",
    "        cv2.circle(img=img, center=(x, y), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "        left_eye.append([x,y])\n",
    "        \n",
    "    for i in range(48, 60):\n",
    "        x = landmarks.part(i).x\n",
    "        y = landmarks.part(i).y\n",
    "        \n",
    "        # Draw a circle\n",
    "        cv2.circle(img=img, center=(x, y), radius=3, color=(0, 255, 0), thickness=-1)\n",
    "        mouth.append([x,y])\n",
    "    print(landmarks.part(42).x)        \n",
    "print(right_eye)\n",
    "print(left_eye)\n",
    "print(mouth)\n",
    "# show the image\n",
    "cv2.imshow(winname=\"Face\", mat=img)\n",
    "\n",
    "# Delay between every fram\n",
    "cv2.waitKey(delay=0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    # return the eye aspect ratio\n",
    "    return ear\n",
    "\n",
    "def avg_eye_aspect_ratio(left,right):\n",
    "    if left == [] and right == []:\n",
    "        return 0\n",
    "    elif left == []:\n",
    "        return eye_aspect_ratio(right)\n",
    "    elif right == []:\n",
    "        return eye_aspect_ratio(left)\n",
    "    else:\n",
    "        return ((eye_aspect_ratio(left) + eye_aspect_ratio(right))/2)\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    if mouth == []:\n",
    "        return 0\n",
    "    A = dist.euclidean(mouth[2], mouth[10])\n",
    "    B = dist.euclidean(mouth[3], mouth[9])\n",
    "    C = dist.euclidean(mouth[4], mouth[8])\n",
    "    D = dist.euclidean(mouth[0], mouth[6])\n",
    "    mar= (A + B + C) / (3.0 * D)\n",
    "    return mar\n",
    "\n",
    "def mouth_over_eye(ear, mar):\n",
    "    return mar/ear\n",
    "\n",
    "# (ratio - mean(ratios))/standard deviation (ratios)\n",
    "\n",
    "def normalization(target, data):\n",
    "    return (target - mean(data))/stdev(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005773502691896262"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdev([0.30,0.31,0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left: 0.3006659262401662\n",
      "Right: 0.3138608051535341\n",
      "Avg: 0.30726336569685014\n",
      "Mouth: 0.3822614674525305\n"
     ]
    }
   ],
   "source": [
    "print(\"Left: \" + str(eye_aspect_ratio(left_eye)))\n",
    "print(\"Right: \" + str(eye_aspect_ratio(right_eye)))\n",
    "print(\"Avg: \" + str(avg_eye_aspect_ratio(left_eye,right_eye)))\n",
    "print(\"Mouth: \" + str(mouth_aspect_ratio(mouth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    path = \"D:/training_data\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    training_data_RATIO = []\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in tqdm(os.listdir(path + \"/\" + person)):\n",
    "            if state == \"0\":\n",
    "                eye_data = []\n",
    "                mouth_data = []\n",
    "                moe_data = []\n",
    "                count = 0\n",
    "                for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                    if count > 20:\n",
    "                        break\n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    right_eye = []\n",
    "                    left_eye = []\n",
    "                    mouth = []\n",
    "            \n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                     # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                        #if face landmarks can be detected\n",
    "                        if landmarks.part(42).x != '':\n",
    "                \n",
    "                    # Loop through all the points\n",
    "                            for n in range(42, 48):\n",
    "                                x = landmarks.part(n).x\n",
    "                                y = landmarks.part(n).y\n",
    "        \n",
    "                                right_eye.append([x,y])\n",
    "\n",
    "                            for j in range(36, 42):\n",
    "                                x = landmarks.part(j).x\n",
    "                                y = landmarks.part(j).y\n",
    "        \n",
    "                                left_eye.append([x,y])\n",
    "        \n",
    "                            for i in range(48, 60):\n",
    "                                x = landmarks.part(i).x\n",
    "                                y = landmarks.part(i).y\n",
    "        \n",
    "                                mouth.append([x,y])\n",
    "                            \n",
    "                            ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                            mar = mouth_aspect_ratio(mouth)\n",
    "                            moe = mouth_over_eye(ear, mar)\n",
    "                            eye_data.append(ear)\n",
    "                            mouth_data.append(mar)\n",
    "                            moe_data.append(moe)\n",
    "                    \n",
    "                        break\n",
    "                    count += 1\n",
    "            counter = 0\n",
    "            filter = 5\n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                if counter % filter == 0:\n",
    "                    \n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    right_eye = []\n",
    "                    left_eye = []\n",
    "                    mouth = []\n",
    "                    info = []\n",
    "            \n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                 # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                    #if face landmarks can be detected\n",
    "                        if landmarks.part(42).x != '':\n",
    "                \n",
    "                # Loop through all the points\n",
    "                            for n in range(42, 48):\n",
    "                                x = landmarks.part(n).x\n",
    "                                y = landmarks.part(n).y\n",
    "        \n",
    "                                right_eye.append([x,y])\n",
    "\n",
    "                            for j in range(36, 42):\n",
    "                                x = landmarks.part(j).x\n",
    "                                y = landmarks.part(j).y\n",
    "        \n",
    "                                left_eye.append([x,y])\n",
    "        \n",
    "                            for i in range(48, 60):\n",
    "                                x = landmarks.part(i).x\n",
    "                                y = landmarks.part(i).y\n",
    "        \n",
    "                                mouth.append([x,y])\n",
    "                        \n",
    "                            ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                            mar = mouth_aspect_ratio(mouth)\n",
    "                            moe = mouth_over_eye(ear, mar)\n",
    "                            info.append(ear)\n",
    "                            info.append(mar)\n",
    "                            info.append(moe)\n",
    "                            info.append(normalization(ear, eye_data))\n",
    "                            info.append(normalization(mar, mouth_data))\n",
    "                            info.append(normalization(moe, moe_data))\n",
    "                            training_data_RATIO.append(np.array(info))\n",
    "                        break\n",
    "                counter += 1\n",
    "                \n",
    "                \n",
    "    np.save(\"training_data_RATIO_shrunk\", training_data_RATIO)\n",
    "    print (\"Done!\")\n",
    "    \n",
    "def create_test_data():\n",
    "    path = \"D:/test_data\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    training_data_RATIO = []\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in tqdm(os.listdir(path + \"/\" + person)):\n",
    "            if state == \"0\":\n",
    "                eye_data = []\n",
    "                mouth_data = []\n",
    "                moe_data = []\n",
    "                count = 0\n",
    "                for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                    if count > 20:\n",
    "                        break\n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    right_eye = []\n",
    "                    left_eye = []\n",
    "                    mouth = []\n",
    "            \n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                     # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                        #if face landmarks can be detected\n",
    "                        if landmarks.part(42).x != '':\n",
    "                \n",
    "                    # Loop through all the points\n",
    "                            for n in range(42, 48):\n",
    "                                x = landmarks.part(n).x\n",
    "                                y = landmarks.part(n).y\n",
    "        \n",
    "                                right_eye.append([x,y])\n",
    "\n",
    "                            for j in range(36, 42):\n",
    "                                x = landmarks.part(j).x\n",
    "                                y = landmarks.part(j).y\n",
    "        \n",
    "                                left_eye.append([x,y])\n",
    "        \n",
    "                            for i in range(48, 60):\n",
    "                                x = landmarks.part(i).x\n",
    "                                y = landmarks.part(i).y\n",
    "        \n",
    "                                mouth.append([x,y])\n",
    "                            \n",
    "                            ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                            mar = mouth_aspect_ratio(mouth)\n",
    "                            moe = mouth_over_eye(ear, mar)\n",
    "                            eye_data.append(ear)\n",
    "                            mouth_data.append(mar)\n",
    "                            moe_data.append(moe)\n",
    "                    \n",
    "                        break\n",
    "                    count += 1\n",
    "            counter = 0\n",
    "            filter = 5\n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                if counter % filter == 0:\n",
    "                    \n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    right_eye = []\n",
    "                    left_eye = []\n",
    "                    mouth = []\n",
    "                    info = []\n",
    "            \n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                 # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                    #if face landmarks can be detected\n",
    "                        if landmarks.part(42).x != '':\n",
    "                \n",
    "                # Loop through all the points\n",
    "                            for n in range(42, 48):\n",
    "                                x = landmarks.part(n).x\n",
    "                                y = landmarks.part(n).y\n",
    "        \n",
    "                                right_eye.append([x,y])\n",
    "\n",
    "                            for j in range(36, 42):\n",
    "                                x = landmarks.part(j).x\n",
    "                                y = landmarks.part(j).y\n",
    "        \n",
    "                                left_eye.append([x,y])\n",
    "        \n",
    "                            for i in range(48, 60):\n",
    "                                x = landmarks.part(i).x\n",
    "                                y = landmarks.part(i).y\n",
    "        \n",
    "                                mouth.append([x,y])\n",
    "                        \n",
    "                            ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                            mar = mouth_aspect_ratio(mouth)\n",
    "                            moe = mouth_over_eye(ear, mar)\n",
    "                            info.append(ear)\n",
    "                            info.append(mar)\n",
    "                            info.append(moe)\n",
    "                            info.append(normalization(ear, eye_data))\n",
    "                            info.append(normalization(mar, mouth_data))\n",
    "                            info.append(normalization(moe, moe_data))\n",
    "                            training_data_RATIO.append(np.array(info))\n",
    "                        break\n",
    "                counter += 1\n",
    "                \n",
    "                \n",
    "    np.save(\"test_data_RATIO_shrunk\", training_data_RATIO)\n",
    "    print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:08,  4.29s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.07s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.02s/it]\u001b[A\n",
      "  2%|▏         | 1/48 [00:09<07:05,  9.06s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.34it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.45s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\u001b[A\n",
      "  4%|▍         | 2/48 [00:13<04:49,  6.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.75s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.54s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\u001b[A\n",
      "  6%|▋         | 3/48 [00:18<04:11,  5.60s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.41s/it]\u001b[A\n",
      "  8%|▊         | 4/48 [00:22<03:42,  5.06s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.51s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.46s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.29s/it]\u001b[A\n",
      " 10%|█         | 5/48 [00:32<04:52,  6.79s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:08<00:16,  8.45s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:13<00:06,  6.50s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.36s/it]\u001b[A\n",
      " 12%|█▎        | 6/48 [00:48<06:57,  9.95s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.61s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\u001b[A\n",
      " 15%|█▍        | 7/48 [00:53<05:37,  8.24s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.74s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.92s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.82s/it]\u001b[A\n",
      " 17%|█▋        | 8/48 [00:58<04:54,  7.36s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.23it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.50it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.47s/it]\u001b[A\n",
      " 19%|█▉        | 9/48 [01:02<04:11,  6.44s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.80s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.37s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.45s/it]\u001b[A\n",
      " 21%|██        | 10/48 [01:10<04:15,  6.72s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:08,  4.18s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.36s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.61s/it]\u001b[A\n",
      " 23%|██▎       | 11/48 [01:21<04:55,  7.98s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.93s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.74s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.85s/it]\u001b[A\n",
      " 25%|██▌       | 12/48 [01:29<04:53,  8.15s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:05<00:10,  5.22s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.54s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.41s/it]\u001b[A\n",
      " 27%|██▋       | 13/48 [01:42<05:39,  9.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.28s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.50s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\u001b[A\n",
      " 29%|██▉       | 14/48 [01:49<04:54,  8.66s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:06,  3.14s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.90s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.86s/it]\u001b[A\n",
      " 31%|███▏      | 15/48 [01:57<04:45,  8.64s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.52it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.52it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\u001b[A\n",
      " 33%|███▎      | 16/48 [01:59<03:32,  6.65s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:08,  4.24s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:08<00:04,  4.10s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.32s/it]\u001b[A\n",
      " 35%|███▌      | 17/48 [02:12<04:24,  8.54s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:07<00:14,  7.06s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:09<00:04,  4.48s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.59s/it]\u001b[A\n",
      " 38%|███▊      | 18/48 [02:26<05:03, 10.12s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.84s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.53s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.75s/it]\u001b[A\n",
      " 40%|███▉      | 19/48 [02:34<04:37,  9.55s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.74s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.53s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.62s/it]\u001b[A\n",
      " 42%|████▏     | 20/48 [02:42<04:13,  9.05s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:06,  3.08s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.48s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.40s/it]\u001b[A\n",
      " 44%|████▍     | 21/48 [02:49<03:49,  8.49s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.58s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.65s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.52s/it]\u001b[A\n",
      " 46%|████▌     | 22/48 [02:54<03:10,  7.31s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.99s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:01,  1.99s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.89s/it]\u001b[A\n",
      " 48%|████▊     | 23/48 [03:00<02:50,  6.82s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:07<00:15,  7.95s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:14<00:07,  7.16s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:19<00:00,  6.42s/it]\u001b[A\n",
      " 50%|█████     | 24/48 [03:19<04:13, 10.55s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.22s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.08it/s]\u001b[A\n",
      " 52%|█████▏    | 25/48 [03:22<03:09,  8.22s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:09,  4.94s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:10<00:05,  5.58s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.91s/it]\u001b[A\n",
      " 54%|█████▍    | 26/48 [03:36<03:43, 10.17s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:06,  3.31s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:06<00:02,  2.96s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.96s/it]\u001b[A\n",
      " 56%|█████▋    | 27/48 [03:45<03:25,  9.79s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.74s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.46s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\u001b[A\n",
      " 58%|█████▊    | 28/48 [03:51<02:49,  8.50s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:08<00:17,  8.51s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:19<00:09,  9.69s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:27<00:00,  9.26s/it]\u001b[A\n",
      " 60%|██████    | 29/48 [04:19<04:31, 14.28s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.85s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.74s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.70s/it]\u001b[A\n",
      " 62%|██████▎   | 30/48 [04:24<03:27, 11.53s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:09,  4.64s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:07<00:03,  3.71s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.54s/it]\u001b[A\n",
      " 65%|██████▍   | 31/48 [04:34<03:11, 11.26s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:07,  3.92s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.79s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.86s/it]\u001b[A\n",
      " 67%|██████▋   | 32/48 [04:43<02:47, 10.46s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:05<00:11,  5.66s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:09<00:04,  4.75s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.41s/it]\u001b[A\n",
      " 69%|██████▉   | 33/48 [04:56<02:49, 11.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.04s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.44s/it]\u001b[A\n",
      " 71%|███████   | 34/48 [05:00<02:08,  9.20s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.04s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.05s/it]\u001b[A\n",
      " 73%|███████▎  | 35/48 [05:07<01:47,  8.29s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.88s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:07<00:03,  3.87s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.87s/it]\u001b[A\n",
      " 75%|███████▌  | 36/48 [05:15<01:40,  8.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:11<00:22, 11.21s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:15<00:06,  6.95s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.28s/it]\u001b[A\n",
      " 77%|███████▋  | 37/48 [05:31<01:56, 10.63s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.42s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.13s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.00s/it]\u001b[A\n",
      " 79%|███████▉  | 38/48 [05:37<01:32,  9.24s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.47s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.70s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.48s/it]\u001b[A\n",
      " 81%|████████▏ | 39/48 [05:44<01:18,  8.70s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.61it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:01<00:00,  1.63it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.68it/s]\u001b[A\n",
      " 83%|████████▎ | 40/48 [05:46<00:53,  6.63s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.77s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.12s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.94s/it]\u001b[A\n",
      " 85%|████████▌ | 41/48 [05:52<00:44,  6.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:09,  4.80s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:08<00:04,  4.09s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.95s/it]\u001b[A\n",
      " 88%|████████▊ | 42/48 [06:04<00:48,  8.03s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:05<00:11,  5.69s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:08<00:03,  3.82s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.12s/it]\u001b[A\n",
      " 90%|████████▉ | 43/48 [06:16<00:46,  9.33s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.47s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:01,  1.96s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.14s/it]\u001b[A\n",
      " 92%|█████████▏| 44/48 [06:23<00:33,  8.46s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:07,  3.71s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.45s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.41s/it]\u001b[A\n",
      " 94%|█████████▍| 45/48 [06:30<00:24,  8.09s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:06<00:13,  6.57s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:13<00:06,  6.74s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.55s/it]\u001b[A\n",
      " 96%|█████████▌| 46/48 [06:47<00:21, 10.66s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.18it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.62s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.42s/it]\u001b[A\n",
      " 98%|█████████▊| 47/48 [06:54<00:09,  9.64s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:07<00:14,  7.38s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:14<00:06,  6.96s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:22<00:00,  7.66s/it]\u001b[A\n",
      "100%|██████████| 48/48 [07:17<00:00,  9.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.63it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:00<00:00,  2.24it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\u001b[A\n",
      "  8%|▊         | 1/12 [00:03<00:35,  3.26s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:06,  3.15s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.66s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\u001b[A\n",
      " 17%|█▋        | 2/12 [00:10<00:55,  5.57s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:05,  2.98s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:05<00:02,  2.69s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.66s/it]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:18<01:00,  6.67s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.64s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.49s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.34s/it]\u001b[A\n",
      " 33%|███▎      | 4/12 [00:28<01:03,  8.00s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:08,  4.06s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:08<00:04,  4.21s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.87s/it]\u001b[A\n",
      " 42%|████▏     | 5/12 [00:40<01:05,  9.31s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.26s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:05<00:00,  1.96s/it]\u001b[A\n",
      " 50%|█████     | 6/12 [00:45<00:48,  8.14s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:03<00:01,  1.54s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.23s/it]\u001b[A\n",
      " 58%|█████▊    | 7/12 [00:49<00:33,  6.69s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:05<00:11,  5.81s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:10<00:05,  5.15s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.79s/it]\u001b[A\n",
      " 67%|██████▋   | 8/12 [01:07<00:40, 10.09s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:03<00:06,  3.25s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:07<00:03,  3.79s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.50s/it]\u001b[A\n",
      " 75%|███████▌  | 9/12 [01:17<00:30, 10.21s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:01,  1.86it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.39s/it]\u001b[A\n",
      " 83%|████████▎ | 10/12 [01:21<00:16,  8.35s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.46s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.45s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.49s/it]\u001b[A\n",
      " 92%|█████████▏| 11/12 [01:29<00:08,  8.07s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:02<00:04,  2.00s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:04<00:02,  2.36s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.15s/it]\u001b[A\n",
      "100%|██████████| 12/12 [01:35<00:00,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_train_data()\n",
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3651145 ,  0.39587182,  1.08424019,  0.06209334, -0.55851786,\n",
       "       -0.34768605])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    path = \"D:/first 1 mintue\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "   \n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in tqdm(os.listdir(path + \"/\" + person)):\n",
    "            test_data_RATIO = []\n",
    "            if state == \"0\":\n",
    "                eye_data = []\n",
    "                mouth_data = []\n",
    "                moe_data = []\n",
    "                count = 0\n",
    "                for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                    if count > 20:\n",
    "                        break\n",
    "                    img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                    faces = detector(img)\n",
    "                    right_eye = []\n",
    "                    left_eye = []\n",
    "                    mouth = []\n",
    "            \n",
    "                    for face in faces:\n",
    "                        x1 = face.left() # left point\n",
    "                        y1 = face.top() # top point\n",
    "                        x2 = face.right() # right point\n",
    "                        y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                     # Create landmark object\n",
    "                        landmarks = predictor(image=img, box=face)\n",
    "                        #if face landmarks can be detected\n",
    "                        if landmarks.part(42).x != '':\n",
    "                \n",
    "                    # Loop through all the points\n",
    "                            for n in range(42, 48):\n",
    "                                x = landmarks.part(n).x\n",
    "                                y = landmarks.part(n).y\n",
    "        \n",
    "                                right_eye.append([x,y])\n",
    "\n",
    "                            for j in range(36, 42):\n",
    "                                x = landmarks.part(j).x\n",
    "                                y = landmarks.part(j).y\n",
    "        \n",
    "                                left_eye.append([x,y])\n",
    "        \n",
    "                            for i in range(48, 60):\n",
    "                                x = landmarks.part(i).x\n",
    "                                y = landmarks.part(i).y\n",
    "        \n",
    "                                mouth.append([x,y])\n",
    "                            \n",
    "                            ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                            mar = mouth_aspect_ratio(mouth)\n",
    "                            moe = mouth_over_eye(ear, mar)\n",
    "                            eye_data.append(ear)\n",
    "                            mouth_data.append(mar)\n",
    "                            moe_data.append(moe)\n",
    "                    \n",
    "                        break\n",
    "                    count += 1\n",
    "                \n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                faces = detector(img)\n",
    "                right_eye = []\n",
    "                left_eye = []\n",
    "                mouth = []\n",
    "                info = []\n",
    "            \n",
    "                for face in faces:\n",
    "                    x1 = face.left() # left point\n",
    "                    y1 = face.top() # top point\n",
    "                    x2 = face.right() # right point\n",
    "                    y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                 # Create landmark object\n",
    "                    landmarks = predictor(image=img, box=face)\n",
    "                    #if face landmarks can be detected\n",
    "                    if landmarks.part(42).x != '':\n",
    "                \n",
    "                # Loop through all the points\n",
    "                        for n in range(42, 48):\n",
    "                            x = landmarks.part(n).x\n",
    "                            y = landmarks.part(n).y\n",
    "        \n",
    "                            right_eye.append([x,y])\n",
    "\n",
    "                        for j in range(36, 42):\n",
    "                            x = landmarks.part(j).x\n",
    "                            y = landmarks.part(j).y\n",
    "        \n",
    "                            left_eye.append([x,y])\n",
    "        \n",
    "                        for i in range(48, 60):\n",
    "                            x = landmarks.part(i).x\n",
    "                            y = landmarks.part(i).y\n",
    "        \n",
    "                            mouth.append([x,y])\n",
    "                        \n",
    "                        ear = avg_eye_aspect_ratio(left_eye,right_eye)\n",
    "                        mar = mouth_aspect_ratio(mouth)\n",
    "                        moe = mouth_over_eye(ear, mar)\n",
    "                        info.append(ear)\n",
    "                        info.append(mar)\n",
    "                        info.append(moe)\n",
    "                        info.append(normalization(ear, eye_data))\n",
    "                        info.append(normalization(mar, mouth_data))\n",
    "                        info.append(normalization(moe, moe_data))\n",
    "                        test_data_RATIO.append(np.array(info))\n",
    "                    break\n",
    "                \n",
    "                \n",
    "            np.save(\"./minute/\" + person + \"/\" + state + \"/\" + \"test_RATIO\", test_data_RATIO)\n",
    "    print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:44<01:28, 44.25s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:14<00:35, 35.95s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:40<00:00, 33.35s/it]\u001b[A\n",
      "  9%|▉         | 1/11 [01:40<16:40, 100.06s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:43<01:27, 43.94s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:29<00:44, 44.61s/it]\u001b[A\n",
      "100%|██████████| 3/3 [02:11<00:00, 43.75s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [03:51<17:45, 118.40s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:27<00:55, 27.69s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:47<00:58, 58.43s/it]\u001b[A\n",
      "100%|██████████| 3/3 [02:43<00:00, 54.63s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [06:35<18:33, 139.18s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:51<01:42, 51.09s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:50<00:55, 55.95s/it]\u001b[A\n",
      "100%|██████████| 3/3 [02:39<00:00, 53.09s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [09:14<17:09, 147.11s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:29<00:58, 29.18s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:51<00:24, 24.90s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:13<00:00, 24.34s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [10:27<12:02, 120.39s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:14<00:29, 14.70s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:36<00:18, 18.98s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:43<00:00, 14.62s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [11:11<07:51, 94.38s/it] \n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [01:10<02:20, 70.13s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:56<00:56, 56.43s/it]\u001b[A\n",
      "100%|██████████| 3/3 [03:25<00:00, 68.51s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [14:36<08:42, 130.71s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:37<01:14, 37.23s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:43<00:54, 54.27s/it]\u001b[A\n",
      "100%|██████████| 3/3 [02:20<00:00, 46.98s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [16:57<06:41, 133.97s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.54s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:27<00:16, 16.16s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:52<00:00, 17.50s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [17:50<03:37, 108.50s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:36<01:12, 36.13s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:14<00:37, 37.39s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:52<00:00, 37.52s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [19:42<01:49, 109.76s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:26<00:53, 26.55s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [01:04<00:33, 33.07s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:33<00:00, 31.18s/it]\u001b[A\n",
      "100%|██████████| 11/11 [21:16<00:00, 116.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21200, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.load(\"test_data_RATIO_v4.npy\")\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data():\n",
    "    path = \"D:/test_data\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    test_data_RATIO = []\n",
    "    for person in tqdm(os.listdir(path)):\n",
    "        for state in os.listdir(path + \"/\" + person):\n",
    "            for img in os.listdir(path + \"/\" + person + \"/\" + state):\n",
    "                img = cv2.cvtColor(cv2.imread(path + \"/\" + person + \"/\" + state + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "                faces = detector(img)\n",
    "                right_eye = []\n",
    "                left_eye = []\n",
    "                mouth = []\n",
    "                info = []\n",
    "            \n",
    "                for face in faces:\n",
    "                    x1 = face.left() # left point\n",
    "                    y1 = face.top() # top point\n",
    "                    x2 = face.right() # right point\n",
    "                    y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "                 # Create landmark object\n",
    "                    landmarks = predictor(image=img, box=face)\n",
    "            \n",
    "                    #check if face landmarks can be detected\n",
    "                    if landmarks.part(42).x !='':\n",
    "    \n",
    "                # Loop through all the points\n",
    "                        for n in range(42, 48):\n",
    "                            x = float(landmarks.part(n).x)\n",
    "                            y = float(landmarks.part(n).y)\n",
    "        \n",
    "                            right_eye.append([x,y])\n",
    "\n",
    "                        for j in range(36, 42):\n",
    "                            x = float(landmarks.part(j).x)\n",
    "                            y = float(landmarks.part(j).y)\n",
    "        \n",
    "                            left_eye.append([x,y])\n",
    "        \n",
    "                        for i in range(48, 60):\n",
    "                            x = float(landmarks.part(i).x)\n",
    "                            y = float(landmarks.part(i).y)\n",
    "        \n",
    "                            mouth.append([x,y])\n",
    "            \n",
    "                        info.append(avg_eye_aspect_ratio(left_eye,right_eye))\n",
    "                        info.append(mouth_aspect_ratio(mouth))\n",
    "                        test_data_RATIO.append(np.array(info))    \n",
    "                    break\n",
    "                \n",
    "    np.save(\"test_data_RATIO_v3\", test_data_RATIO)\n",
    "    print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [07:10<00:00, 35.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 606/606 [00:12<00:00, 47.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def create_test_data_video():\n",
    "    path = \"D:/test_data/50/0\"\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    # Load the predictor\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "    test_data_RATIO = []\n",
    "    #for person in tqdm(os.listdir(path)):\n",
    "        #for state in os.listdir(path + \"/\" + person):\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        #if counter < 0:\n",
    "        #check if face is recognizable\n",
    "        img = cv2.cvtColor(cv2.imread(path + \"/\" + img), cv2.COLOR_BGR2RGB)\n",
    "        faces = detector(img)\n",
    "        right_eye = []\n",
    "        left_eye = []\n",
    "        mouth = []\n",
    "        info = []\n",
    "            \n",
    "        for face in faces:\n",
    "            x1 = face.left() # left point\n",
    "            y1 = face.top() # top point\n",
    "            x2 = face.right() # right point\n",
    "            y2 = face.bottom() # bottom point\n",
    "   \n",
    "\n",
    "            # Create landmark object\n",
    "            landmarks = predictor(image=img, box=face)\n",
    "            \n",
    "            #check if face landmarks can be detected\n",
    "            if landmarks.part(42).x !='':\n",
    "    \n",
    "        # Loop through all the points\n",
    "                for n in range(42, 48):\n",
    "                    x = float(landmarks.part(n).x)\n",
    "                    y = float(landmarks.part(n).y)\n",
    "        \n",
    "                    right_eye.append([x,y])\n",
    "\n",
    "                for j in range(36, 42):\n",
    "                    x = float(landmarks.part(j).x)\n",
    "                    y = float(landmarks.part(j).y)\n",
    "        \n",
    "                    left_eye.append([x,y])\n",
    "        \n",
    "                for i in range(48, 60):\n",
    "                    x = float(landmarks.part(i).x)\n",
    "                    y = float(landmarks.part(i).y)\n",
    "        \n",
    "                    mouth.append([x,y])\n",
    "            \n",
    "                info.append(avg_eye_aspect_ratio(left_eye,right_eye))\n",
    "                info.append(mouth_aspect_ratio(mouth))\n",
    "                test_data_RATIO.append(np.array(info))    \n",
    "            break\n",
    "                \n",
    "    np.save(\"ratio_50_0\", test_data_RATIO)\n",
    "    print (\"Done!\")\n",
    "    \n",
    "create_test_data_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2] *",
   "language": "python",
   "name": "conda-env-tensorflow2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
